# Global LLM configuration
[llm]
model = "deepseek-r1-250120"
#model = "deepseek-v3-250324"
#model = "deepseek-v3-241226"
base_url = "https://ark.cn-beijing.volces.com/api/v3"
api_key = "d5d9437dd7-87effe-4816-9ed9-273e447ec84e"
max_tokens = 8192
temperature = 0.4

# [llm] #AZURE OPENAI: 
# api_type= 'azure'
# model = "YOUR_MODEL_NAME" #"gpt-4o-mini"
# base_url = "{YOUR_AZURE_ENDPOINT.rstrip('/')}/openai/deployments/{AZURE_DEPOLYMENT_ID}"
# api_key = "AZURE API KEY"
# max_tokens = 8096
# temperature = 0.0
# api_version="AZURE API VERSION" #"2024-08-01-preview"

# Optional configuration for specific LLM models
[llm.vision]
model = "deepseek-r1-250120"
#model = "deepseek-v3-250324"
#model = "deepseek-v3-241226"
base_url = "https://ark.cn-beijing.volces.com/api/v3"
api_key = "d5d9437dd7-87effe-4816-9ed9-273e447ec84e"

# Server configuration
[server]
host = "127.0.0.1"
port = 5172

#模型推荐支持Function Calling
#qwen-max
#qwen-plus
#qwen-turbo
#qwen-long
#qwen-vl-plus-latest(視覺模型)
